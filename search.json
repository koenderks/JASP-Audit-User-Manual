[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JASP for Audit",
    "section": "",
    "text": "Preface\nThe JASP for Audit User Manual provides detailed instructions and best practices for working with the Audit module in the free and open-source software JASP. It covers various aspects, including data import, analysis techniques, and interpretation of results. The manual is curated by the Statistical Auditing Group at Nyenrode Business University, ensuring that users have access to reliable and up-to-date information.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Getting Started",
    "section": "",
    "text": "Downloading JASP\nStatistical theory is fundamental to many auditing procedures. To perform these procedures effectively, auditors need user-friendly software for statistical analyses and the knowledge to interpret the results. JASP (JASP Team, 2025) is an open-source, free-of-charge, cross-platform statistical software program that supports statistical auditing through its Audit module (Derks et al., 2021).\nThe Audit module (i.e., JASP for Audit) allows auditors to plan, execute, and interpret a wide range of statistical auditing procedures using state-of-the-art statistical methods, thereby reducing programming errors and simplifying the process. Tailored for auditors, the module features an intuitive interface that aligns with audit processes and international standards on auditing. In addition to standard frequentist methods, the Audit module incorporates Bayesian methods to enhance audit transparency and efficiency by utilizing existing information.\nIn summary, the Audit module takes care of the complex statistical work, allowing you to concentrate on interpreting the results of your analysis. The remaining paragraphs in this chapter discuss how to get started using JASP for Audit.\nJASP for Audit is part of JASP, which can be freely downloaded from www.jasp-stats.org. Click the ‘Download JASP’ button on the homepage to access the download page and choose your preferred installation. JASP is available for Windows, MacOS, Linux, and Chrome OS.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "introduction.html#enabling-the-audit-module",
    "href": "introduction.html#enabling-the-audit-module",
    "title": "Getting Started",
    "section": "Enabling the Audit module",
    "text": "Enabling the Audit module\nAfter opening JASP, you will see the following main menu bar at the top of the screen.\n\n\n\n\n\nTo find the Audit module, click the ‘+’ icon on the right of this menu bar. A different menu will appear on the right side which shows all available modules. Check the box next to ‘Audit’ to make the module visible in the main menu bar. You can now access the Audit module and its analyses by clicking its module icon in the menu bar (see image below).",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "introduction.html#accessibility",
    "href": "introduction.html#accessibility",
    "title": "Getting Started",
    "section": "Accessibility",
    "text": "Accessibility\nThe Audit module is a robust tool for statistical auditing. The following paragraphs detail its accessibility features, including where to locate help files and how to the reliability of the statistical results is ensured.\n\nHelp files\nOnce you open an analysis in the Audit module, you can click the blue ‘i’ icon next to the analysis title to access a help file that explains its functionality. Additional help files for certain options can be accessed by clicking the blue ‘i’ icon next to those options.\n\n\n\n\n\n\n\nValidation of statistical results\nThe statistical results generated by the Audit module are based on the R package jfa (Derks, 2025). For comprehensive documentation and information on the benchmarks used for validation, please visit the package website at https://koenderks.github.io/jfa/.\n\n\n\n\n\n\nDerks, K. (2025). jfa: Statistical methods for auditing. https://doi.org/10.32614/CRAN.package.jfa\n\n\nDerks, K., de Swart, J., Wagenmakers, E., Wille, J., & Wetzels, R. (2021). JASP for Audit: Bayesian tools for the auditing practice. Journal of Open Source Software, 6(68), 2733.\n\n\nJASP Team. (2025). JASP (Version 0.19.3)[Computer software]. https://jasp-stats.org/",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "chap-workflow.html",
    "href": "chap-workflow.html",
    "title": "1  Sampling Workflow",
    "section": "",
    "text": "1.1 The four stages of the sampling workflow\nThe goal of statistical audit sampling is to infer the misstatement in a population based on a representative sample. This can be challenging, but the Audit module simplifies the process into four stages: planning, selection, execution, and evaluation.\nMore detailed information about the individual stages in the audit sampling workflow is provided below.\nIn the planning stage, you determine the sample size needed to support the assertion that the population’s misstatement is below the performance materiality. This involves using prior audit outcomes and information about inherent risk and control risk. Expectations about error rates also influence the sample size required to maintain statistical confidence.\nUsing the sample size from the planning stage, you select a statistically representative sample. Each sampling unit receives an inclusion probability, and units are selected based on these probabilities. Monetary unit sampling assigns probabilities to individual monetary units, making higher-value items more likely to be selected. Record sampling assigns equal probabilities to all items.\nIn the execution stage, you assess the correctness of selected items. The simplest method categorizes items as correct or incorrect, while a more accurate method considers the true value (audit value) of items. Annotating samples with audit values provides a more precise estimate of misstatement. If book values are unavailable, use the correct/incorrect method.\nIn the evaluation stage, you use the annotated sample to infer the total misstatement in the population. Statistical techniques calculate a projected maximum misstatement, and the population is approved if this is below the performance materiality.\nThis manual emphasizes the practical application of the audit sampling workflow in JASP. For a deeper understanding of the statistical theory behind the four stages of the audit sampling workflow, read the free online book Statistical Audit Sampling with R.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Workflow</span>"
    ]
  },
  {
    "objectID": "chap-workflow.html#a-practical-example-in-jasp",
    "href": "chap-workflow.html#a-practical-example-in-jasp",
    "title": "1  Sampling Workflow",
    "section": "1.2 A practical example in JASP",
    "text": "1.2 A practical example in JASP\nThe Audit module in JASP offers two ways to navigate the audit sampling workflow: the Sampling Workflow analysis, which guides you through all four stages, and individual analyses for Planning, Selection, and Evaluation. This chapter uses the classical sampling workflow analysis to explain the Audit module’s core functionality. Note that a Bayesian variant of the sampling workflow is also available.\nLet’s explore an example of the audit sampling workflow. To follow along, open the ‘Testing for Overstatements’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Testing for Overstatements’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with three columns: ‘ID’, ‘bookValue’, and ‘auditValue’. The ‘ID’ column represents the identification number of the items in the population. The ‘bookValue’ column shows the recorded values of the items, while the ‘auditValue’ column displays the true values. The ‘auditValue’ column is included for illustrative purposes, as auditors typically know the true values only for the audited sample, not for all items in the population.\n\n\n\n\n\n\n1.2.1 Stage 1: Planning\nTo start the sampling workflow, click on the Audit module icon and select ‘Sampling Workflow’. This will open the following interface, where you need to fill in the options for the statistical analysis.\n\n\n\n\n\nThe following steps are required:\n\nIndicate the variables: First, enter the variable indicating the identification numbers of the items in the corresponding box. Optionally, if you have access to the book values of the items, you can enter this variable as well.\nSampling objectives: Next, formulate your sampling objectives. Enable the ‘Performance materiality’ objective if you want to test whether the total misstatement in the population exceeds a certain limit (i.e., the performance materiality). This approach allows you to plan a sample such that, when the sample meets your expectations, the maximum error is said to be below performance materiality. Enable the ‘Minimum precision’ objective if you want to obtain a required minimum precision when estimating the total misstatement in the population. This approach allows you to plan a sample such that, when the sample meets expectations, the uncertainty of your estimate is within a tolerable percentage. In the example, we choose a performance materiality of 3.5%.\nExpected misstatement: Then, indicate how many misstatements are tolerable in the sample. In the example, we choose to tolerate one full misstatement in the sample.\nPrior information: Additionally, indicate the risks of material misstatement via the audit risk model. According to the Audit Risk Model, audit risk can be divided into three constituents: inherent risk, control risk, and detection risk. Inherent risk is the risk posed by an error in a financial statement due to a factor other than a failure of internal controls. Control risk is the probability that a material misstatement is not prevented or detected by the internal control systems of the company (e.g., computer-managed databases). Both these risks are commonly assessed by the auditor on a 3-point scale consisting of low, medium, and high. Detection risk is the probability that an auditor will fail to find material misstatements in an organization’s financial statements. For a given level of audit risk, the tolerable level of detection risk bears an inverse relationship to the other two assessed risks. Intuitively, a greater risk of material misstatement should require a lower tolerable detection risk and, accordingly, more persuasive audit evidence. In this example, we choose to set all risks to ‘High’ and solely rely on evidence from substantive testing.\n\nThe primary output from the planning stage, shown below, indicates that a minimum sample size of 134 sampling units is required to achieve 95% assurance that the misstatement in the population is below 3.5%, while allowing for one misstatement in the sample.\n\n\n\n\n\n\nNext stage: Finally, progress to the selection stage by clicking the ‘To Selection’ button.\n\nFor a more detailed explanation of the options and output in the planning stage, see Chapter 2.\n\n\n1.2.2 Stage 2: Selection\nIn the selection stage, you must select the 134 sampling units from the population. Once the ‘To Selection’ button is pressed, the interface from the selection stage opens.\n\n\n\n\n\nThe following steps are required:\n\nRandomness options: Begin by selecting the options related to randomness in the selection procedure. The seed option is important as it ensures that random procedures are reproducible, allowing for consistent results across multiple runs. A random number will be chosen each time you start the analysis. Additionally, the ‘Randomize item order’ option is available to randomly shuffle the rows in the dataset, which can help mitigate any biases that might arise from the original order of the data.\nSampling units: Next, specify the sampling units for the selection process. These units can either be items or monetary units. If no book value variable is provided, the sampling units default to ‘Items’, enabling attribute sampling. Conversely, if a book value variable was indicated during the planning stage, the sampling units default to ‘Monetary units’, facilitating monetary unit sampling (MUS). MUS is particularly useful for auditing financial data as it considers the monetary value of each unit.\nSampling method: Then, choose the selection method to be used in the sampling process. The available algorithms include:\n\nFixed interval sampling: This method selects units at regular intervals from the dataset, ensuring a systematic sampling approach.\nCell sampling: This technique involves dividing the dataset into cells and randomly selecting units from each cell, promoting a systematic sampling approach with a bit of randomness.\nRandom sampling: This approach randomly selects units from the entire dataset, providing a simple yet effective method for ensuring randomness.\n\n\nThe primary output from the selection stage, as shown in the first table below, reveals that 134 sampling units were selected from 134 items. The sample’s total value amounts to €67,821.22, representing 4.8% of the total population value. The second table provides details specific to interval selection using monetary unit sampling. It indicates the number of items selected in the ‘Top stratum’, which includes all items larger than a single interval (for fixed interval selection). In this instance, there were 0 items in the top stratum.\n\n\n\n\n\n\nNext stage: Finally, progress to the execution stage by clicking the ‘To Execution’ button.\n\n\n\n1.2.3 Stage 3: Execution\nIn the execution stage, you must judge the fairness of the 134 sampled items. Once the ‘To Execution’ button is pressed, the interface from the execution stage opens.\n\n\n\n\n\nThe following steps are required:\n\nAnnotation method: First, decide how to annotate the selected items. You have two options:\n\nAudit value: Annotate the items with their audit (true) values. This method is recommended (and automatically selected) when the items have a monetary value.\nCorrect / Incorrect: Annotate the items as correct (0) or incorrect (1). This method is recommended (and automatically selected) when the items do not have a monetary value.\n\nColumn names: Next, specify the names of the two columns that will be added to the dataset. The first column name will indicate the result of the selection, while the second column name will contain the annotation of the items. Click the ‘Continue’ button to confirm the options and open the data viewer.\nAnnotating items: Then, use the data viewer to annotate the selected items with their book value. For example, in this case, item 50826 (row 25, highlighted in red) had a book value of €333.03 but a true value of €200. The remaining items have correctly reported book values.\nNext stage: Finally, progress to the evaluation stage by clicking the ‘To Evaluation’ button.\n\n\n\n1.2.4 Stage 4: Evaluation\nIn the evaluation stage, you assess the misstatement in the sample and extrapolate it to the entire population. Once you press the ‘To Evaluation’ button, the interface for the evaluation stage will open.\n\n\n\n\n\nThe following steps are required:\n\nAnnotation variable: Specify the variable that contains the annotation of the items in the corresponding box.\nAdditional tablaes: It is recommended to request the ‘Misstated items’ table from the ‘Report’ section. This table displays the items in the sample where the book value did not match the true value. Additional tables and figures to clarify the output, which will be discussed in Chapter 4, can be requested here as well.\n\nThe primary output from the evaluation stage, as shown in the first table below, indicates that the most likely misstatement in the population is estimated to be 0.003, or 0.3%. The 95% upper bound for this estimate is 0.027, or 2.7%. This upper bound is lower than the performance materiality of 3.5%, meaning the auditor has achieved at least 95% assurance that the population misstatement is below the performance materiality.\n\n\n\n\n\nBased on the results of this statistical analysis, the auditor concludes that the population is free of material misstatement.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Workflow</span>"
    ]
  },
  {
    "objectID": "chap-benford.html",
    "href": "chap-benford.html",
    "title": "5  Benford’s Law",
    "section": "",
    "text": "5.1 A practical example in JASP\nBenford’s law states that the distribution of leading digits in a population naturally follows a certain distribution. In auditing, assessing whether a distribution of digits in the population conforms to Benford’s law may provide additional evidence that the transactions in the population might need further investigation. Non-conformity to Benford’s law does not necessarily indicate fraud. A Benford’s law analysis should therefore only be used to acquire insight into whether a population might need further investigation.\nLet’s explore an example analysis of Benford’s law. To follow along, open the ‘Assessing Benford’s Law’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Assessing Benford’s Law’ (not the green JASP-icon button).\nThe interface…\nThe first table in the output…\nThe second table in the output…\nThe figure in the output…",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Benford's Law</span>"
    ]
  },
  {
    "objectID": "chap-bunching.html",
    "href": "chap-bunching.html",
    "title": "6  Repeated Values",
    "section": "",
    "text": "6.1 A practical example in JASP\nThe repeated values analysis analyzes the frequency with which values get repeated within a dataset (called “number-bunching”) to statistically identify whether the data were likely tampered with. Unlike Benford’s law this approach examines the entire number at once, not only the first or last digit (Simohnsohn, 2019).\nTo determine whether the data show an excessive amount of bunching, the null hypothesis that the data do not contain an unexpected amount of repeated values is tested. To quantify what is expected, this test requires the assumption that the integer portions of the numbers are not associated with their decimal portions.",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Repeated Values</span>"
    ]
  },
  {
    "objectID": "chap-bunching.html#a-practical-example-in-jasp",
    "href": "chap-bunching.html#a-practical-example-in-jasp",
    "title": "6  Repeated Values",
    "section": "",
    "text": "Simohnsohn, U. (2019). Number-bunching: A new tool for forensic data analysis. http://datacolada.org/77",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Repeated Values</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Derks, K. (2025). jfa: Statistical\nmethods for auditing. https://doi.org/10.32614/CRAN.package.jfa\n\n\nDerks, K., de Swart, J., Wagenmakers, E., Wille, J., & Wetzels, R.\n(2021). JASP for Audit: Bayesian\ntools for the auditing practice. Journal of Open Source\nSoftware, 6(68), 2733.\n\n\nJASP Team. (2025). JASP (Version\n0.19.3)[Computer software]. https://jasp-stats.org/\n\n\nSimohnsohn, U. (2019). Number-bunching: A new tool for forensic data\nanalysis. http://datacolada.org/77",
    "crumbs": [
      "References"
    ]
  }
]