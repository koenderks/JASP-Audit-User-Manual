[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JASP for Audit",
    "section": "",
    "text": "Preface\nThe JASP for Audit User Manual provides detailed instructions and best practices for working with the Audit module in the free and open-source software JASP. It covers various aspects, including data import and export, analysis techniques, and interpretation of results.\nThe Statistical Auditing Group at Nyenrode Business University, which develops and maintains JASP for Audit, curates the manual to ensure users have accurate and up-to-date information.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Getting Started",
    "section": "",
    "text": "Downloading JASP\nStatistical theory is fundamental to many auditing procedures. To perform these procedures effectively, auditors need user-friendly software for statistical analyses and the knowledge to interpret the results. JASP (JASP Team, 2025) is an open-source, free-of-charge, cross-platform statistical software program that supports statistical auditing through its Audit module (Derks et al., 2021).\nThe Audit module (i.e., JASP for Audit) allows auditors to plan, execute, and interpret a wide range of statistical auditing procedures using state-of-the-art statistical methods, thereby reducing programming errors and simplifying the process. Tailored for auditors, the module features an intuitive interface that aligns with audit processes and international standards on auditing. In addition to standard frequentist methods, the Audit module incorporates Bayesian methods to enhance audit transparency and efficiency by utilizing existing information.\nIn summary, the Audit module takes care of the complex statistical work, allowing you to concentrate on interpreting the results of your analysis. The remaining paragraphs in this chapter discuss how to get started using JASP for Audit.\nJASP for Audit is part of JASP, which can be freely downloaded from www.jasp-stats.org. Click the ‘Download JASP’ button on the homepage to access the download page and choose your preferred installation. JASP is available for Windows, MacOS, Linux, and Chrome OS.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "introduction.html#enabling-the-audit-module",
    "href": "introduction.html#enabling-the-audit-module",
    "title": "Getting Started",
    "section": "Enabling the Audit module",
    "text": "Enabling the Audit module\nAfter opening JASP, you will see the following main menu bar at the top of the screen.\n\n\n\n\n\nTo find the Audit module, click the ‘+’ icon on the right of this menu bar. A different menu will appear on the right side which shows all available modules. Check the box next to ‘Audit’ to make the module visible in the main menu bar. You can now access the Audit module and its analyses by clicking its module icon in the menu bar (see image below).",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "introduction.html#accessibility",
    "href": "introduction.html#accessibility",
    "title": "Getting Started",
    "section": "Accessibility",
    "text": "Accessibility\nThe Audit module is a robust tool for statistical auditing. The following paragraphs detail its accessibility features, including where to locate help files and how to the reliability of the statistical results is ensured.\n\nHelp files\nOnce you open an analysis in the Audit module, you can click the blue ‘i’ icon next to the analysis title to access a help file that explains its functionality. Additional help files for certain settings can be accessed by clicking the blue ‘i’ icon next to those settings.\n\n\n\n\n\n\n\nValidation of statistical results\nThe statistical results generated by the Audit module are based on the R package jfa (Derks, 2025). For comprehensive documentation and information on the benchmarks used for validation, please visit the package website at https://koenderks.github.io/jfa/.\n\n\n\n\n\n\nDerks, K. (2025). jfa: Statistical methods for auditing. https://doi.org/10.32614/CRAN.package.jfa\n\n\nDerks, K., de Swart, J., Wagenmakers, E., Wille, J., & Wetzels, R. (2021). JASP for Audit: Bayesian tools for the auditing practice. Journal of Open Source Software, 6(68), 2733.\n\n\nJASP Team. (2025). JASP (Version 0.19.3)[Computer software]. https://jasp-stats.org/",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "chap-workflow.html",
    "href": "chap-workflow.html",
    "title": "1  Sampling Workflow",
    "section": "",
    "text": "1.1 The four stages of the sampling workflow\nThe goal of statistical audit sampling is to infer the misstatement in a population based on a representative sample. This can be challenging, but the Audit module simplifies the process into four stages: planning, selection, execution, and evaluation.\nMore detailed information about the individual stages in the audit sampling workflow is provided below.\nIn the planning stage, you determine the sample size needed to support the assertion that the population’s misstatement is below the performance materiality. This involves using prior audit outcomes and information about inherent risk and control risk. Expectations about error rates also influence the sample size required to maintain statistical confidence.\nUsing the sample size from the planning stage, you select a statistically representative sample. Each sampling unit receives an inclusion probability, and units are selected based on these probabilities. Monetary unit sampling assigns probabilities to individual monetary units, making higher-value items more likely to be selected. Record sampling assigns equal probabilities to all items.\nIn the execution stage, you assess the correctness of selected items. The simplest method categorizes items as correct or incorrect, while a more accurate method considers the true value (audit value) of items. Annotating samples with audit values provides a more precise estimate of misstatement. If book values are unavailable, use the correct/incorrect method.\nIn the evaluation stage, you use the annotated sample to infer the total misstatement in the population. Statistical techniques calculate a projected maximum misstatement, and the population is approved if this is below the performance materiality.\nThis manual emphasizes the practical application of the audit sampling workflow in JASP. For a deeper understanding of the statistical theory behind the four stages of the audit sampling workflow, read the free online book Statistical Audit Sampling with R.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Workflow</span>"
    ]
  },
  {
    "objectID": "chap-workflow.html#practical-example",
    "href": "chap-workflow.html#practical-example",
    "title": "1  Sampling Workflow",
    "section": "1.2 Practical example",
    "text": "1.2 Practical example\nThe Audit module in JASP offers two ways to navigate the audit sampling workflow: the Sampling Workflow analysis, which guides you through all four stages, and individual analyses for Planning, Selection, and Evaluation. This chapter uses the classical sampling workflow analysis to explain the Audit module’s core functionality. Note that a Bayesian variant of the sampling workflow is also available.\nLet’s explore an example of the audit sampling workflow. To follow along, open the ‘Testing for Overstatements’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Testing for Overstatements’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 3500 rows and three columns: ‘ID’, ‘bookValue’, and ‘auditValue’. The ‘ID’ column represents the identification number of the items in the population. The ‘bookValue’ column shows the recorded values of the items, while the ‘auditValue’ column displays the true values. The ‘auditValue’ column is included for illustrative purposes, as auditors typically know the true values only for the audited sample, not for all items in the population.\n\n\n\n\n\n\n1.2.1 Stage 1: Planning\nTo start the sampling workflow, click on the Audit module icon and select ‘Sampling Workflow’. This will open the following interface, where you need to specify the settings for the statistical analysis.\n\n\n\n\n\nThe following five settings are required:\n\nIndicate the variables: First, enter the variable indicating the identification numbers of the items in the corresponding box. Optionally, if you have access to the book values of the items, you can enter this variable as well.\nSampling objectives: Next, formulate your sampling objectives. Enable the ‘Performance materiality’ objective if you want to test whether the total misstatement in the population exceeds a certain limit (i.e., the performance materiality). This approach allows you to plan a sample such that, when the sample meets your expectations, the maximum error is said to be below performance materiality. Enable the ‘Minimum precision’ objective if you want to obtain a required minimum precision when estimating the total misstatement in the population. This approach allows you to plan a sample such that, when the sample meets expectations, the uncertainty of your estimate is within a tolerable percentage. In the example, we choose a performance materiality of 3.5%.\nExpected misstatement: Then, indicate how many misstatements are tolerable in the sample. In the example, we choose to tolerate one full misstatement in the sample.\nPrior information: Additionally, indicate the risks of material misstatement via the audit risk model. According to the Audit Risk Model, audit risk can be divided into three constituents: inherent risk, control risk, and detection risk. Inherent risk is the risk posed by an error in a financial statement due to a factor other than a failure of internal controls. Control risk is the probability that a material misstatement is not prevented or detected by the internal control systems of the company (e.g., computer-managed databases). Both these risks are commonly assessed by the auditor on a 3-point scale consisting of low, medium, and high. Detection risk is the probability that an auditor will fail to find material misstatements in an organization’s financial statements. For a given level of audit risk, the tolerable level of detection risk bears an inverse relationship to the other two assessed risks. Intuitively, a greater risk of material misstatement should require a lower tolerable detection risk and, accordingly, more persuasive audit evidence. In this example, we choose to set all risks to ‘High’ and solely rely on evidence from substantive testing.\n\nThe primary output from the planning stage, shown below, indicates that a minimum sample size of 134 sampling units is required to achieve 95% assurance that the misstatement in the population is below 3.5%, while allowing for one misstatement in the sample.\n\n\n\n\n\n\nNext stage: Finally, progress to the selection stage by clicking the ‘To Selection’ button.\n\nFor a more detailed explanation of the settings and output in the planning stage, see Chapter 2.\n\n\n1.2.2 Stage 2: Selection\nIn the selection stage, you must select the 134 sampling units from the population. Once the ‘To Selection’ button is pressed, the interface from the selection stage opens.\n\n\n\n\n\nThe following four settings are required:\n\nRandomness: Begin by selecting the settings related to randomness in the selection procedure. The seed setting is important as it ensures that random procedures are reproducible, allowing for consistent results across multiple runs. A random number will be chosen each time you start the analysis. Additionally, the ‘Randomize item order’ setting is available to randomly shuffle the rows in the dataset, which can help mitigate any biases that might arise from the original order of the data.\nSampling units: Next, specify the sampling units for the selection process. These units can either be items or monetary units. If no book value variable is provided, the sampling units default to ‘Items’, enabling attribute sampling. Conversely, if a book value variable was indicated during the planning stage, the sampling units default to ‘Monetary units’, facilitating monetary unit sampling (MUS). MUS is particularly useful for auditing financial data as it considers the monetary value of each unit.\nSampling method: Then, choose the selection method to be used in the sampling process. The available algorithms include:\n\n\nFixed interval sampling: This method selects units at regular intervals from the dataset, ensuring a systematic sampling approach.\nCell sampling: This technique involves dividing the dataset into cells and randomly selecting units from each cell, promoting a systematic sampling approach with a bit of randomness.\nRandom sampling: This approach randomly selects units from the entire dataset, providing a simple yet effective method for ensuring randomness.\n\nThe primary output from the selection stage, as shown in the first table below, reveals that 134 sampling units were selected from 134 items. The sample’s total value amounts to €67,821.22, representing 4.8% of the total population value. The second table provides details specific to interval selection using monetary unit sampling. It indicates the number of items selected in the ‘Top stratum’, which includes all items larger than a single interval (for fixed interval selection). In this instance, there were 0 items in the top stratum.\n\n\n\n\n\n\nNext stage: Finally, progress to the execution stage by clicking the ‘To Execution’ button.\n\n\n\n1.2.3 Stage 3: Execution\nIn the execution stage, you must judge the fairness of the 134 sampled items. Once the ‘To Execution’ button is pressed, the interface from the execution stage opens.\n\n\n\n\n\nThe following four settings are required:\n\nAnnotation method: First, decide how to annotate the selected items. You have two choices:\n\nAudit value: Annotate the items with their audit (true) values. This method is recommended (and automatically selected) when the items have a monetary value.\nCorrect / Incorrect: Annotate the items as correct (0) or incorrect (1). This method is recommended (and automatically selected) when the items do not have a monetary value.\n\nColumn names: Next, specify the names of the two columns that will be added to the dataset. The first column name will indicate the result of the selection, while the second column name will contain the annotation of the items. Click the ‘Continue’ button to confirm the settings and open the data viewer.\nAnnotating items: Then, use the data viewer to annotate the selected items with their book value. For example, in this case, item 50826 (row 25, highlighted in red) had a book value of €333.03 but a true value of €200. The remaining items have correctly reported book values.\nNext stage: Finally, progress to the evaluation stage by clicking the ‘To Evaluation’ button.\n\n\n\n1.2.4 Stage 4: Evaluation\nIn the evaluation stage, you assess the misstatement in the sample and extrapolate it to the entire population. Once you press the ‘To Evaluation’ button, the interface for the evaluation stage will open.\n\n\n\n\n\nThe following setting is required:\n\nAnnotation variable: Specify the variable that contains the annotation of the items in the corresponding box.\n\nThe following setting is optional:\n\nAdditional tables: It is recommended to request the ‘Misstated items’ table from the ‘Report’ section. This table displays the items in the sample where the book value did not match the true value. Additional tables and figures to clarify the output, which will be discussed in Chapter 4, can be requested here as well.\n\nThe primary output from the evaluation stage, as shown in the first table below, indicates that the most likely misstatement in the population is estimated to be 0.003, or 0.3%. The 95% upper bound for this estimate is 0.027, or 2.7%. This upper bound is lower than the performance materiality of 3.5%, meaning the auditor has achieved at least 95% assurance that the population misstatement is below the performance materiality.\n\n\n\n\n\nBased on the results of this statistical analysis, the auditor concludes that the population is free of material misstatement.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Workflow</span>"
    ]
  },
  {
    "objectID": "chap-planning.html",
    "href": "chap-planning.html",
    "title": "2  Planning",
    "section": "",
    "text": "2.1 Purpose of the analysis\nThis page is about the ‘Planning’ analysis in the ‘Audit Sampling’ section of the module.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planning</span>"
    ]
  },
  {
    "objectID": "chap-planning.html#practical-example",
    "href": "chap-planning.html#practical-example",
    "title": "2  Planning",
    "section": "2.2 Practical example",
    "text": "2.2 Practical example\n\n2.2.1 Main settings\n\n\n\n\n\nThese are the main settings for the analysis:\n\nSampling objectives: Performance materiality: …\nSampling objectives: Minimum precision: …\nConfidence: …\nExpected misstatements: …\nPopulation: No. units: …\nAudit risk model: …\n\n\n\n\n\nDisplay: Explanatory text: …\n\n\n\n2.2.2 Main output\n\n\n\n\n\n\n\n2.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nPlots: Compare sample sizes: …\n\n\n\n\n\nPlots: Presumed data distribution: …\n\n\n\n\n\nFormat output: …\n\n\n\n2.2.4 Advanced\nThe following advanced settings allow you to customize the statistical computations according to your preferences.\n\n\n\n\n\n\nLikelihood: …\nIterations: Increment: …\nIterations: Maximum:",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planning</span>"
    ]
  },
  {
    "objectID": "chap-selection.html",
    "href": "chap-selection.html",
    "title": "3  Selection",
    "section": "",
    "text": "3.1 Purpose of the analysis\nThis page is about the ‘Selection’ analysis in the ‘Audit Sampling’ section of the module.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Selection</span>"
    ]
  },
  {
    "objectID": "chap-selection.html#practical-example",
    "href": "chap-selection.html#practical-example",
    "title": "3  Selection",
    "section": "3.2 Practical example",
    "text": "3.2 Practical example\nLet’s explore an example of a selection analysis. To follow along, open the ‘Testing for Overstatements’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Testing for Overstatements’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 3500 rows and three columns: ‘ID’, ‘bookValue’, and ‘auditValue’. The ‘ID’ column represents the identification number of the items in the population. The ‘bookValue’ column shows the recorded values of the items, while the ‘auditValue’ column displays the true values. The ‘auditValue’ column is included for illustrative purposes, as auditors typically know the true values only for the audited sample, not for all items in the population.\n\n\n\n\n\n\n3.2.1 Main settings\n\n\n\n\n\nThese are the main settings for the analysis:\n\nVariables: …\nSample size …\nRandomize item order: …\nSampling units: …\nSelection method: …\n\nFixed interval sampling: Starting point: …\n\nDisplay: Explanatory text: …\n\n\n\n3.2.2 Main output\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Descriptive statistics: …\n\n\n\n\n\nTables: Selected items: …\n\nOrder by book value: …\n\n\n\n\n\n\n\n\n\n3.2.4 Export\nThe following settings enable you to export the sample to a .csv file.\n\n\n\n\n\n\nColumn name selection result: …\nFile name: …\nEnable synchronization: …",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Selection</span>"
    ]
  },
  {
    "objectID": "chap-evaluation.html",
    "href": "chap-evaluation.html",
    "title": "4  Evaluation",
    "section": "",
    "text": "4.1 Purpose of the analysis\nThis page is about the ‘Evaluation’ analysis in the ‘Audit Sampling’ section of the module.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chap-evaluation.html#practical-example",
    "href": "chap-evaluation.html#practical-example",
    "title": "4  Evaluation",
    "section": "4.2 Practical example",
    "text": "4.2 Practical example\nLet’s explore an example of an evaluation analysis. To follow along, open the ‘Evaluating a Sample’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Evaluating a Sample’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 90 rows and three columns: ‘ID’, ‘Book.value’, ‘Audit.value’. The ‘ID’ column represents the identification number of the items in the population. The ‘Book.value’ and ‘Audit.value’ columns show the recorded and true values of the items, respectively.\n\n\n\n\n\n\n4.2.1 Main settings\n\n\n\n\n\nThese are the main settings for the analysis:\n\nSampling objectives: Performance materiality: …\nSampling objectives: Minimum precision: …\nConfidence: …\nData type: …\nPopulation: No. items: …\nPopulation: No. units: …\nAudit risk model: …\nDisplay: Explanatory text: …\n\n\n\n4.2.2 Main output\n\n\n\n\n\n\n\n4.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Misstated items: …\n\n\n\n\n\nTables: Corrections to population: …\n\n\n\n\n\nPlots: Sampling objectives: …\n\n\n\n\n\nPlots: Estimates: …\n\n\n\n\n\n\n\n\n4.2.4 Advanced\nThe following advanced settings allow you to customize the statistical computations according to your preferences.\n\n\n\n\n\n\nMethod: …\nCritical items: …\nConfidence interval (Alt. hypothesis): …",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chap-estimation.html",
    "href": "chap-estimation.html",
    "title": "5  True Value Estimation",
    "section": "",
    "text": "5.1 Purpose of the analysis\nThis page is about the ‘True Value Estimation’ analysis in the ‘Audit Sampling’ section of the module.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>True Value Estimation</span>"
    ]
  },
  {
    "objectID": "chap-estimation.html#practical-example",
    "href": "chap-estimation.html#practical-example",
    "title": "5  True Value Estimation",
    "section": "5.2 Practical example",
    "text": "5.2 Practical example\nLet’s explore an example analysis of a true value estimation analysis. To follow along, open the ‘Evaluating a Stratified Sample’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Evaluating a Stratified Sample’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 1414 rows and five columns: ‘ID’, ‘Stratum’, ‘BookValue’, ‘AuditValue’, and ‘Selected’. The ‘ID’ column represents the identification number of the items in the population. The ‘Stratum’ column shows the location from which the item was retrieved. The ‘BookValue’ and ‘AuditValue’ columns show the recorded and true values of the items, respectively. Finally, the ‘Selected’ column shows which items were selected to be included in the sample.\n\n\n\n\n\n\n5.2.1 Main settings\n\n\n\n\n\nThese are the main settings for the analysis:\n\nPopulation: No. items: …\nPopulation: No. units: …\nMethod: …\nDisplay: Explanatory text: …\nDisplay: Confidence: …\n\n\n\n5.2.2 Main output\n\n\n\n\n\n\n\n5.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Required sample size: …\n\n\n\n\n\nPlots: Scatter plot: …",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>True Value Estimation</span>"
    ]
  },
  {
    "objectID": "chap-benford.html",
    "href": "chap-benford.html",
    "title": "6  Benford’s Law",
    "section": "",
    "text": "6.1 Purpose of the analysis\nThis page is about the ‘Benford’s Law’ analysis in the ‘Data Auditing’ section of the module.\nBenford’s law states that the distribution of leading digits in a population naturally follows a certain distribution. In auditing, assessing whether a distribution of digits in the population conforms to Benford’s law may provide additional evidence that the items or transactions in a population might need further investigation.",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Benford's Law</span>"
    ]
  },
  {
    "objectID": "chap-benford.html#practical-example",
    "href": "chap-benford.html#practical-example",
    "title": "6  Benford’s Law",
    "section": "6.2 Practical example",
    "text": "6.2 Practical example\nLet’s explore an example analysis of Benford’s law. To follow along, open the ‘Assessing Benford’s Law’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Assessing Benford’s Law’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 772 rows and two columns: ‘ID’ and ‘value’. The ‘ID’ column represents the identification number of the items in the population. The ‘value’ column shows the recorded values of the items.\n\n\n\n\n\n\n6.2.1 Main settings\nThe interface of the Benford’s law analysis in JASP is shown below. We will investigate whether the distribution of first digits in the variable ‘value’, which represents the recorded values of transactions in a financial population, adheres to Benford’s law. That is, the null hypothesis, H\\(_0\\), states that the distribution of first digits follows Benford’s law, while the alternative hypothesis, H\\(_1\\), states that it does not.\n\n\n\n\n\nThese are the main settings for the analysis:\n\nVariable: Begin by entering the variable whose digit distribution you wish to test in the designated box. In the example, this is the variable ‘value’, so we drag this variable to the field on the right.\nConfidence: Indicate the confidence level for your analysis. This level, which complements the significance level, determines when to reject the null hypothesis. In the example, we use a confidence level of 95%.\nReference: Select a reference distribution to compare the chosen digits against. By default, this is set to ‘Benford’s law,’ but you can also opt for a uniform distribution. In the example, we select ‘Benford’s law’.\nDigits: Choose which digits to compare against the reference distribution. You can select the first digits (default), the first two digits, or the last digits. Benford’s law typically applies to the first or first two digits, while the uniform distribution is usually applied to the last digits. In the example, we choose to test the first digits against Benford’s law.\nBayes factor: Select which Bayes factor is displayed in the main output table. ‘BF\\(_{10}\\)’ represents the Bayes factor in favor of the alternative hypothesis over the null hypothesis, ‘BF\\(_{01}\\)’ represents the Bayes factor in favor of the null hypothesis over the alternative hypothesis, and ‘Log(BF\\(_{10}\\))’ represents the logarithm of BF\\(_{10}\\).\nDisplay: Explanatory text: Finally, select whether to show explanatory text in the output.\n\n\n\n6.2.2 Main output\nThe main table in the output, shown below, shows the sample size (n), the mean absolute deviation (MAD), the chi-square value (\\(X^2\\)) and its degrees of freedom (df). The table shows a p-value of 0.478, indicating that H\\(_0\\) should not be rejected at a significance level of 5%. Furthermore, the table presents the Bayes factor in favor of the null hypothesis, BF\\(_{01}\\), which is 6.9x10\\(^6\\). This suggests that the data provide very strong evidence supporting H\\(_0\\) over H\\(_1\\).\n\n\n\n\n\nNote that non-conformity to Benford’s law does not necessarily indicate fraud. A Benford’s law analysis should therefore only be used to acquire insight into whether a population might need further investigation.\n\n\n6.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Frequency table: Check this box to display a table of the observed and expected frequencies of the digits. Clicking the ‘Confidence interval’ option shows confidence intervals for the observed relative frequencies in the table.\nThe frequency table displays the observed count for each leading digit in the second column. Adjacent to this, it shows the expected relative frequency under Benford’s law alongside the observed relative frequency in the data. Additionally, p-values and Bayes factors are provided to test whether the observed relative frequencies differ from the expected ones. In this case, only the digit 8 has a p-value smaller than 0.05, indicating a significant deviation from the expected relative frequency under Benford’s law.\n\n\n\n\n\nTables: Matched rows: Check this box to display a table showing the rows that have a certain number as their leading/last digit(s).\nIn the example, we request a table of rows that match the digit 8. The first column displays the row number where the digit is found, and the second column shows the matched value. Using this table, you can identify the transactions that may warrant further investigation.\n\n\n\n\n\nPlots: Observed vs. expected: Check this box to display a figure that illustrates the observed frequencies compared to the expected frequencies.\nThe figure in the output visualizes the observed relative frequencies compared to the expected ones, with the digit 8 highlighted in red. From this figure, it is immediately clear that the transactions starting with the digit 8 may warrant further inspection.\n\n\n\n\n\nPlots: Bayes factor robustness check: Check this box to display a figure that shows the Bayes factor under different specifications of the prior concentration parameter.\nThe figure below is referred to as a robustness check. If the Bayes factor supports a particular hypothesis across all reasonable values of the prior concentration parameter, the result is considered robust regarding the choice of prior distribution. In this instance, the figure demonstrates that the Bayes factor consistently provides evidence in favor of the null hypothesis, regardless of the prior concentration parameter values.\n\n\n\n\n\nPlots: Sequential analysis: Select this box to display a figure illustrating the Bayes factor as a function of sample size, across various prior specifications.\nIn the example analysis, the sequential analysis plot demonstrates that the Bayes factor provides increasing evidence in favor of H\\(_0\\) as the sample size grows. Additionally, this evidence is more pronounced when using a more concentrated prior distribution.\n\n\n\n\n\n\n\n\n6.2.4 Advanced\nThe following advanced settings allow you to customize the statistical computations according to your preferences.\n\n\n\n\n\n\nPrior distribution: Concentration: Specify the concentration parameter for the Dirichlet prior distribution. Adjusting this value will alter the Bayes factor in the main output table. A larger concentration parameter indicates a more concentrated prior distribution, suggesting that the population proportions are more similar. When testing against the uniform distribution, this implies a stronger belief in H\\(_0\\). Conversely, when testing against Benford’s law, it indicates a stronger belief in H\\(_1\\).",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Benford's Law</span>"
    ]
  },
  {
    "objectID": "chap-bunching.html",
    "href": "chap-bunching.html",
    "title": "7  Repeated Values",
    "section": "",
    "text": "7.1 Purpose of the analysis\nThis page is about the ‘Repeated Values’ analysis in the ‘Data Auditing’ section of the module.\nThe repeated values analysis analyzes the frequency with which values get repeated within a dataset (called “number-bunching”) to statistically identify whether the data were likely tampered with. Unlike Benford’s law this approach examines the entire number at once, not only the first or last digit (Simohnsohn, 2019).\nTo determine whether the data show an excessive amount of bunching, the null hypothesis that the data do not contain an unexpected amount of repeated values is tested. To quantify what is expected, this test requires the assumption that the integer portions of the numbers are not associated with their decimal portions.",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Repeated Values</span>"
    ]
  },
  {
    "objectID": "chap-bunching.html#practical-example",
    "href": "chap-bunching.html#practical-example",
    "title": "7  Repeated Values",
    "section": "7.2 Practical example",
    "text": "7.2 Practical example\nLet’s explore an example analysis of repeated values. To follow along, open the ‘Assessing Benford’s Law’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Assessing Benford’s Law’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 772 rows and two columns: ‘ID’ and ‘value’. The ‘ID’ column represents the identification number of the items in the population. The ‘value’ column shows the recorded values of the items.\n\n\n\n\n\n\n7.2.1 Main settings\nThe interface …\n\n\n\n\n\nThese are the main settings for the analysis:\n\nVariable: …\nTests: Average frequency …\nTests: Entropy …\nShuffle decimal digits: …\nDisplay: Explanatory text: …\nDisplay: Confidence: …\n\n\n\n7.2.2 Main output\n\n\n\n\n\n\n\n7.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Assumption checks: …\n\n\n\n\n\nTables: Frequency table: …\n\n\n\n\n\nPlots: Observed vs. expected: …\n\n\n\n\n\nPlots: Histogram: …\n\n\n\n\n\n\n\n\n7.2.4 Advanced\nThe following advanced settings allow you to customize the statistical computations according to your preferences.\n\n\n\n\n\n\nBootstrap: Number of samples: …\nBootstrap: Seed: …\n\n\n\n\n\n\n\nSimohnsohn, U. (2019). Number-bunching: A new tool for forensic data analysis. http://datacolada.org/77",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Repeated Values</span>"
    ]
  },
  {
    "objectID": "chap-fairness-workflow.html",
    "href": "chap-fairness-workflow.html",
    "title": "8  Fairness Workflow",
    "section": "",
    "text": "8.1 Purpose of the analysis\nThis page is about the fairness workflow.",
    "crumbs": [
      "Algorithm Auditing",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Fairness Workflow</span>"
    ]
  },
  {
    "objectID": "chap-fairness-workflow.html#practical-example",
    "href": "chap-fairness-workflow.html#practical-example",
    "title": "8  Fairness Workflow",
    "section": "8.2 Practical example",
    "text": "8.2 Practical example\n\n8.2.1 Main settings\n\n\n8.2.2 Main output\n\n\n8.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.",
    "crumbs": [
      "Algorithm Auditing",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Fairness Workflow</span>"
    ]
  },
  {
    "objectID": "chap-fairness.html",
    "href": "chap-fairness.html",
    "title": "9  Evaluation",
    "section": "",
    "text": "9.1 Purpose of the analysis\nThis page is about the ‘Evaluation’ analysis in the ‘Algorithm Auditing’ section of the module.",
    "crumbs": [
      "Algorithm Auditing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chap-fairness.html#practical-example",
    "href": "chap-fairness.html#practical-example",
    "title": "9  Evaluation",
    "section": "9.2 Practical example",
    "text": "9.2 Practical example\n\n9.2.1 Main settings\n\n\n9.2.2 Main output\n\n\n9.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n9.2.4 Advanced\nThe following advanced settings allow you to customize the statistical computations according to your preferences.",
    "crumbs": [
      "Algorithm Auditing",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Derks, K. (2025). jfa: Statistical\nmethods for auditing. https://doi.org/10.32614/CRAN.package.jfa\n\n\nDerks, K., de Swart, J., Wagenmakers, E., Wille, J., & Wetzels, R.\n(2021). JASP for Audit: Bayesian\ntools for the auditing practice. Journal of Open Source\nSoftware, 6(68), 2733.\n\n\nJASP Team. (2025). JASP (Version\n0.19.3)[Computer software]. https://jasp-stats.org/\n\n\nSimohnsohn, U. (2019). Number-bunching: A new tool for forensic data\nanalysis. http://datacolada.org/77",
    "crumbs": [
      "References"
    ]
  }
]